procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]rt")] <- "Art"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]ssist")] <- "Assistant"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]ttor")] <- "Attorney"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Bb]usiness")] <- "Business"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]linical")] <- "Clinical"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]ommunications")] <- "Communication"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]omputer")] <- "Computer"
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
#Everyone with a job status of Unemployed with a blank occupation is assigned the value Unemployed for their occupation
procrastination_data$Job[procrastination_data$WorkStatus=="unemployed"& procrastination_data$Job==""] <- "Unemployed"
#All Job titles under 5 characters were made to an empty string
procrastination_data$Job[nchar(procrastination_data$Job)<5] <- ""
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
#All jobs with a slash(/) had all text after the slash removed
procrastination_data$Job<-sub("\\s*/.*", "", procrastination_data$Job)
#All jobs with parantheses had the parantheses removed
procrastination_data$Job<-sub("\\s*\\(.*", "", procrastination_data$Job)
#All jobs with leading and trailing white space were trimmed
procrastination_data$Job<-gsub("^\\s+|\\s+$", "", procrastination_data$Job)
procrastination_data$Job<-camelpreserve(procrastination_data$Job)
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
procrastination_data$Gender[procrastination_data$Gender ==""] <- "NA"
procrastination_data$WorkStatus[procrastination_data$WorkStatus ==""] <- "NA"
#This is a function to combine multiple tables of scraped data that share a similar category
bindData <- function(firstframe,dataset,category){
#Here we are assigning the columns we need to some temporary variables and renaming the columns
working_temp <- dataset[[firstframe]][2:nrow(dataset[[firstframe]]),c(3,4)]
names(working_temp)<-c("Country","HDI")
working_temp1 <- dataset[[firstframe+1]][2:nrow(dataset[[firstframe+1]]),c(3,4)]
names(working_temp1)<-c("Country","HDI")
#We are binding the rows of our two temp variables and adding the Category value.
working_temp<-rbind(working_temp,working_temp1)
working_temp<-cbind(working_temp,"Category"=category)
}
url <- "https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index"
HDI_table <- url %>%
read_html() %>%
html_nodes("table")%>%
html_table(fill=TRUE)
HDI <- data.frame("Country","HDI","Category")
HDI<-rbind(bindData(4,HDI_table,"Very high human development"),
bindData(7,HDI_table,"High human development"),
bindData(10,HDI_table,"Medium human development"),
bindData(13,HDI_table,"Low human development"))
#We are doing a left merge of the procrastination data on the HDI data pulled from wikipedia. This means that if there is a missing country value from the procrastination data we will still bring that data over with missing HDI information.
merged_data<-merge(x=procrastination_data,y=HDI,by="Country",all.x=TRUE)
cleaned_data <- merged_data[merged_data$Age>18 & !is.na(merged_data$Age),]
# make columns into proper data types
cleaned_data$Sons <- as.numeric(cleaned_data$Sons)
cleaned_data$HDI <- as.numeric(cleaned_data$HDI )
agesummary <- summary(cleaned_data$Age)
incomesummary <-summary(cleaned_data$Income)
HDIsummary <- summary(cleaned_data$HDI)
agesummary
incomesummary
HDIsummary
meanGPsummary <- summary(cleaned_data$GPMean)
meanAIPSsummary <-summary(cleaned_data$AIPMean)
meanSWLsummary <-summary(cleaned_data$SWLSMean)
meanDPsummary <- summary(cleaned_data$DPMean)
meanGPsummary
meanAIPSsummary
meanSWLsummary
meanDPsummary
#histogram of age
qplot(cleaned_data$Age,
geom="histogram",
binwidth = 10,
main = "Histogram for Age",
xlab = "Age",
fill=I("light blue"),
col=I("red"))+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
#histogram of mean GP
qplot(cleaned_data$GPMean,
geom="histogram",
binwidth = 0.5,
main = "Histogram for Mean GP",
xlab = "Mean GP Score",
fill=I("light blue"),
col=I("red"))+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
frequencyOfRespondantsByGender <- as.data.frame(table(cleaned_data$Gender))
colnames(frequencyOfRespondantsByGender) <- c("Gender","Number of Participants")
kable(frequencyOfRespondantsByGender[order(-frequencyOfRespondantsByGender$`Number of Participants`),],row.names = FALSE)
frequencyOfRespondantsByWork <- as.data.frame(table(cleaned_data$WorkStatus))
colnames(frequencyOfRespondantsByWork) <- c("WorkStatus","Number of Participants")
kable(frequencyOfRespondantsByWork[order(-frequencyOfRespondantsByWork$`Number of Participants`),],row.names = FALSE)
frequencyOfRespondantsByJob<- as.data.frame(table(cleaned_data$Job))
colnames(frequencyOfRespondantsByJob) <- c("Job","Number of Participants")
kable(head(frequencyOfRespondantsByJob[order(-frequencyOfRespondantsByJob$`Number of Participants`),],20),row.names = FALSE)
cleaned_data$Country[cleaned_data$Country==""] <- "NA"
frequencyOfRespondantsByCountry <- as.data.frame(table(cleaned_data$Country))
colnames(frequencyOfRespondantsByCountry) <- c("Country","Number of Participants")
kable(head(frequencyOfRespondantsByCountry[order(-frequencyOfRespondantsByCountry$`Number of Participants`),],20),row.names = FALSE)
cleaned_data$matching <- ifelse(cleaned_data$SelfQuestion ==cleaned_data$OthQuestion,1,0)
matched <-sum(cleaned_data$matching)
matched
top15 <- aggregate(cleaned_data$GPMean,list(cleaned_data$Country),mean)
names(top15) <- c("Country", "GPMean")
merged15 <- merge(x=top15,y=HDI,by='Country',all.x =TRUE)
merged15$GPMean <- round(merged15$GPMean,3)
merged15<- merged15[with(merged15,order(-GPMean)),]
merged15 <- merged15[1:15,]
kable(merged15,row.names = FALSE)
ggplot(merged15, aes(reorder(Country, GPMean),GPMean)) +
geom_bar(stat="identity", aes(fill=Category))+  scale_fill_hue(h = c(5, 100)) +
ggtitle('Top 15 Nations In Average Procrastination Scores(GP)')+
ylab('Average Procrastination Scores(GP)')+
xlab('Country')+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
AIPtop15 <- aggregate(cleaned_data$AIPMean,list(cleaned_data$Country),mean)
names(AIPtop15) <- c("Country", "AIPMean")
AIPmerged15 <- merge(x=AIPtop15,y=HDI,by='Country',all.x =TRUE)
AIPmerged15$AIPMean <- round(AIPmerged15$AIPMean,3)
AIPmerged15<- AIPmerged15[with(AIPmerged15,order(-AIPMean)),]
AIPmerged15<- AIPmerged15[1:15,]
kable(AIPmerged15,row.names = FALSE)
ggplot(AIPmerged15, aes(reorder(Country, AIPMean),AIPMean)) +
geom_bar(stat="identity", aes(fill=Category))+  scale_fill_hue(h = c(5, 100)) +
ggtitle('Top 15 Nations In Average Procrastination Scores(AIP)')+
ylab('Average Procrastination Scores(AIP)')+
xlab('Country')+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
countrymatching<-intersect(merged15$Country,AIPmerged15$Country)
countrymatching <- data.frame(countrymatching)
names(countrymatching) <- c('Country/Region')
countrymatching
#scatter plot
ggplot(data=subset(cleaned_data,Gender=="Male"|Gender=="Female"), aes(Age, Income),color=Gender) + geom_jitter(aes(color=Gender)) +
scale_color_manual(breaks = c("Female", "Male", ""), values=c("red", "blue", "green")) +
geom_smooth(method='lm',mapping=aes(x=Age,y=Income,color=Gender))+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
#linear regression
AgeIncome <- lm(Income~Age,data = cleaned_data)
lmsummary <- summary(AgeIncome)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(AgeIncome)
#scatter plot
ggplot(data=subset(cleaned_data,Gender=="Male"|Gender=="Female"), aes(HDI, SWLSMean),color=Gender) + geom_jitter(aes(color=Gender),na.rm = TRUE) +
scale_color_manual(breaks = c("Female", "Male", ""), values=c("red", "blue", "green")) +
geom_smooth(method='lm',mapping=aes(x=HDI,y=SWLSMean,color=Gender),na.rm = TRUE)+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
#scatter plot of HDI category
ggplot(cleaned_data, aes(Category, SWLSMean)) +
geom_bar(stat="identity", aes(fill=Category))+  scale_fill_hue(h = c(5, 100)) +
ylab('Life Satisfaction Mean Score')+
xlab('HDI Category')+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
HDIout <- write.csv(HDI, "../Output/HDI.csv", row.names=FALSE)
cleaned_data <- write.csv(cleaned_data, "../Output/cleaned_data.csv", row.names=FALSE)
top15GP <- write.csv(merged15, "../Output/GP15.csv", row.names=FALSE)
top15AIP <- write.csv(AIPmerged15, "../Output/AIP15.csv", row.names=FALSE)
procrastination_data <- read.csv("Data/Procrastination.csv",stringsAsFactors = FALSE)
procrastination_data <- read.csv("Data/Procrastination.csv",stringsAsFactors = FALSE)
kable(dim(procrastination_data), header = "Dimension of procrastination dataset")
#a function that removes all of the periods from variable names and makes the name into Camel Case form.
camel <- function(x){ #function for camel case
capit <- function(x) paste0(toupper(substring(x, 1, 1)), substring(x, 2, nchar(x)))
sapply(strsplit(x, "\\."), function(x) paste(capit(x), collapse=""))
}
names(procrastination_data)<-camel(names(procrastination_data))
#a manual update of variable names that are too long or not descriptive.
procrastination_data<- rename(x=procrastination_data,replace=c("HowLongHaveYouHeldThisPositionYears"="ExpYears", "Edu"="Education",
"CountryOfResidence"="Country",
"ÏAge"="Age",
"HowLongHaveYouHeldThisPositionMonths"="ExpMonths",
"DoYouConsiderYourselfAProcrastinator"="SelfQuestion",
"NumberOfDaughters" = "Daughters",
"NumberOfSons" = "Sons",
"CurrentOccupation"="Job",
"CommunitySize"="Community",
"MaritalStatus"="Marital",
"DoOthersConsiderYouAProcrastinator"="OthQuestion",
"AnnualIncome"="Income"))
#This will rename the columns of the different questionnaires
colnames(procrastination_data)[grep(names(procrastination_data),pattern = "GP")] <- sprintf("GPQues%d",1:length(grep(names(procrastination_data),pattern = "GP")))
colnames(procrastination_data)[grep(names(procrastination_data),pattern = "AIP")] <- sprintf("AIPQues%d",1:length(grep(names(procrastination_data),pattern = "AIP")))
colnames(procrastination_data)[grep(names(procrastination_data),pattern = "SWLS")] <- sprintf("SWLSQues%d",1:length(grep(names(procrastination_data),pattern = "SWLS")))
colnames(procrastination_data)[grep(names(procrastination_data),pattern = "DP")] <- sprintf("DPQues%d",1:length(grep(names(procrastination_data),pattern = "DP")))
#Years of experience
#For years of experience any unrealistic value or null value is assigned
procrastination_data$ExpYears <-as.numeric(procrastination_data$ExpYears)
procrastination_data$ExpYears[procrastination_data$ExpYears==999 | is.na(procrastination_data$ExpYears)] <- 0
procrastination_data$ExpYears <- round(procrastination_data$ExpYears,digits=1)
#We are replacing mis identified
procrastination_data$Job[procrastination_data$Job=="0"] <- "NA"
#Any blank income is assigned a value of 0
procrastination_data$Income[is.na(procrastination_data$Income)] <- 0
procrastination_data$Sons[procrastination_data$Sons=="Male"] <- "1"
procrastination_data$Sons[procrastination_data$Sons=="Female"] <- "2"
#We are truncating all values of age after the decimal
procrastination_data$Age <- trunc(procrastination_data$Age,digits=0)
#This is to replace all 0 values of Country with an empty string
procrastination_data$Country[procrastination_data$Country=="0"] <- "NA"
#Any blank answers in the procrastination questionnaires are assigned a Yes value
procrastination_data$OthQuestion[procrastination_data$OthQuestion==""] <- "NA"
procrastination_data$SelfQuestion[procrastination_data$SelfQuestion==""] <- "NA"
procrastination_data$SelfQuestion[procrastination_data$SelfQuestion == '0'] <- "NA"
procrastination_data$SelfQuestion[procrastination_data$SelfQuestion == '4'] <- "NA"
#Here we are greping all of the variables with certain criteria in their names and creating a new variable of the mean of variables
procrastination_data$GPMean <- rowMeans(procrastination_data[,grep(names(procrastination_data),pattern = "GP")])
procrastination_data$AIPMean <- rowMeans(procrastination_data[,grep(names(procrastination_data),pattern = "AIP")])
procrastination_data$SWLSMean <- rowMeans(procrastination_data[,grep(names(procrastination_data),pattern = "SWLS")])
procrastination_data$DPMean <- rowMeans(procrastination_data[,grep(names(procrastination_data),pattern = "DP")])
#We are rounding the characters to only 1 digit after the decimal
procrastination_data$GPMean <- round(procrastination_data$GPMean,digits=1)
procrastination_data$AIPMean <- round(procrastination_data$AIPMean,digits=1)
camelpreserve <- function(x){ #function for camel case
capit <- function(temp_x) {
temp_x<-tolower(temp_x)
paste0(toupper(substring(temp_x, 1, 1)), substring(temp_x, 2, nchar(temp_x)))
}
capit2 <- function(temp_x) {
paste0(toupper(substring(temp_x, 1, 1)), substring(temp_x, 2, nchar(temp_x)))
}
x2<-sapply(strsplit(x, "[ ]+"), function(x) paste(capit(x), collapse=" "))
sapply(strsplit(x2, "\\-"), function(x2) paste(capit2(x2), collapse="-"))
}
#Any job title where the person filled in please specify is made into an empty string.
procrastination_data$Job[grep(procrastination_data$Job,pattern = "please specify")] <- "NA"
#All students are titled as student. As well if someone put their work status as Student then their occupation was updated to student
procrastination_data$Job[grep(procrastination_data$WorkStatus,pattern = "[sS]tudent")] <- "Student"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[sS]tudent")] <- "Student"
#These are statements to make professional job titles more general, i.e. yoga teacher and ESL teacher were simplified to teacher
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[tT]eacher")] <- "Teacher"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[wW]riter")] <- "Writer"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "RN|[nN]urse|LPN|PCA")] <- "Nurse"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[cC][ ]*[eE][ ]*[oO]|[Cc]hief")] <- "Executive"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "IT|[Nn]etwork")] <- "Information Technology"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[dD]octor|[mM][dD]")] <- "Doctor"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[sS]ales")] <- "Sales"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]cademic")] <- "Academic"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Pp]roducer")] <- "Producer"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Ss]upervis")] <- "Supervisor"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Dd]esigner")] <- "Designer"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Ff]inanc|[Bb]ank")] <- "Finance"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Ss]oftware")] <- "Software Developer"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "houswife|\\Shome|^home")] <- "Homemaker"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Ee]ngineer")] <- "Engineer"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Rr]eal [Ee]state")] <- "Real Estate"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]dmin")] <- "Administration"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]nalyst")] <- "Analyst"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]rt")] <- "Art"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]ssist")] <- "Assistant"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Aa]ttor")] <- "Attorney"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Bb]usiness")] <- "Business"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]linical")] <- "Clinical"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]ommunications")] <- "Communication"
procrastination_data$Job[grep(procrastination_data$Job,pattern = "[Cc]omputer")] <- "Computer"
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
#Everyone with a job status of Unemployed with a blank occupation is assigned the value Unemployed for their occupation
procrastination_data$Job[procrastination_data$WorkStatus=="unemployed"& procrastination_data$Job==""] <- "Unemployed"
#All Job titles under 5 characters were made to an empty string
procrastination_data$Job[nchar(procrastination_data$Job)<5] <- ""
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
#All jobs with a slash(/) had all text after the slash removed
procrastination_data$Job<-sub("\\s*/.*", "", procrastination_data$Job)
#All jobs with parantheses had the parantheses removed
procrastination_data$Job<-sub("\\s*\\(.*", "", procrastination_data$Job)
#All jobs with leading and trailing white space were trimmed
procrastination_data$Job<-gsub("^\\s+|\\s+$", "", procrastination_data$Job)
procrastination_data$Job<-camelpreserve(procrastination_data$Job)
procrastination_data$Job[procrastination_data$Job==""] <- "NA"
procrastination_data$Gender[procrastination_data$Gender ==""] <- "NA"
procrastination_data$WorkStatus[procrastination_data$WorkStatus ==""] <- "NA"
#This is a function to combine multiple tables of scraped data that share a similar category
bindData <- function(firstframe,dataset,category){
#Here we are assigning the columns we need to some temporary variables and renaming the columns
working_temp <- dataset[[firstframe]][2:nrow(dataset[[firstframe]]),c(3,4)]
names(working_temp)<-c("Country","HDI")
working_temp1 <- dataset[[firstframe+1]][2:nrow(dataset[[firstframe+1]]),c(3,4)]
names(working_temp1)<-c("Country","HDI")
#We are binding the rows of our two temp variables and adding the Category value.
working_temp<-rbind(working_temp,working_temp1)
working_temp<-cbind(working_temp,"Category"=category)
}
url <- "https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index"
HDI_table <- url %>%
read_html() %>%
html_nodes("table")%>%
html_table(fill=TRUE)
HDI <- data.frame("Country","HDI","Category")
HDI<-rbind(bindData(4,HDI_table,"Very high human development"),
bindData(7,HDI_table,"High human development"),
bindData(10,HDI_table,"Medium human development"),
bindData(13,HDI_table,"Low human development"))
#We are doing a left merge of the procrastination data on the HDI data pulled from wikipedia. This means that if there is a missing country value from the procrastination data we will still bring that data over with missing HDI information.
merged_data<-merge(x=procrastination_data,y=HDI,by="Country",all.x=TRUE)
cleaned_data <- merged_data[merged_data$Age>18 & !is.na(merged_data$Age),]
# make columns into proper data types
cleaned_data$Sons <- as.numeric(cleaned_data$Sons)
cleaned_data$HDI <- as.numeric(cleaned_data$HDI )
agesummary <- summary(cleaned_data$Age)
incomesummary <-summary(cleaned_data$Income)
HDIsummary <- summary(cleaned_data$HDI)
agesummary
incomesummary
HDIsummary
meanGPsummary <- summary(cleaned_data$GPMean)
meanAIPSsummary <-summary(cleaned_data$AIPMean)
meanSWLsummary <-summary(cleaned_data$SWLSMean)
meanDPsummary <- summary(cleaned_data$DPMean)
meanGPsummary
meanAIPSsummary
meanSWLsummary
meanDPsummary
#histogram of age
qplot(cleaned_data$Age,
geom="histogram",
binwidth = 10,
main = "Histogram for Age",
xlab = "Age",
fill=I("light blue"),
col=I("red"))+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
#histogram of mean GP
qplot(cleaned_data$GPMean,
geom="histogram",
binwidth = 0.5,
main = "Histogram for Mean GP",
xlab = "Mean GP Score",
fill=I("light blue"),
col=I("red"))+
theme(plot.title=element_text(hjust = .5), axis.ticks.y=element_blank(),axis.ticks.x=element_blank()) +
theme(axis.text.x = element_text(angle=60,hjust=1))
#load the libraries
library(ggplot2)
library(olsrr)
library(car)
library(caret)
#read the data
training <- read.csv('train.csv')
#subset the nerighborhoods century21 sells: NAmes,Edwards and BrkSide
training1 <- training[which(training$Neighborhood %in% c('NAmes' , 'Edwards' , 'BrkSide')), ]
#subset the price,living area and neighborhood
ID <- training1$Id
price <- training1$SalePrice
livingarea <- training1$GrLivArea
neighborhood <- training1$Neighborhood
areaPER100 <- livingarea/100
#data frame them into analysis1
analysis1 <- data.frame(ID,livingarea,areaPER100,neighborhood, price)
#correct the levels in analysis1 data set
analysis1$neighborhood <- factor(analysis1$neighborhood)
###########################   plot separately first to check the pattern and decide whether transformation is needed    ###########################
#NAmes
NAmes <- analysis1[analysis1$neighborhood=='NAmes',]
#scatter plot of NAmes,tranformation needed
ggplot(NAmes, aes(x=areaPER100, y=price))+
geom_point()
#Edwards
Edwards <- analysis1[analysis1$neighborhood=='Edwards',]
#scatter plot of Edwards,transformation needed
ggplot(Edwards, aes(x=areaPER100, y=price))+
geom_point()
#BrkSide
BrkSide <- analysis1[analysis1$neighborhood=='BrkSide',]
#scatter plot of BrkSide,transformation needed(the scatter is better than the other 2)
ggplot(BrkSide, aes(x=areaPER100, y=price))+
geom_point()
#plot in general
ggplot(analysis1, aes(x=areaPER100, y=price, color = neighborhood))+
geom_point()
############################################ all tranformation adding to the analysis data set ###################################################
analysis1$logprice <- log(analysis1$price)
analysis1$logarea100 <- log(analysis1$areaPER100)
###################tried all transformations and decided to go with logged livingarea vs log price as the transformation  ######################
#logged data scattter plot
#NAmes
NAmes <- analysis1[analysis1$neighborhood=='NAmes',]
#scatter plot of NAmes,tranformation needed
ggplot(NAmes, aes(x=logarea100, y=logprice))+
geom_point()
#Edwards
Edwards <- analysis1[analysis1$neighborhood=='Edwards',]
#scatter plot of Edwards,transformation needed
ggplot(Edwards, aes(x=logarea100, y=logprice))+
geom_point()
#BrkSide
BrkSide <- analysis1[analysis1$neighborhood=='BrkSide',]
#scatter plot of BrkSide,transformation needed(the scatter is better than the other 2)
ggplot(BrkSide, aes(x=logarea100, y=logprice))+
geom_point()
#logged data scatter plot
ggplot(analysis1, aes(x=logarea100, y=logprice, color = neighborhood))+
geom_point()
######################### multiple regression with all neighborhoods, using logged data, no interaction############################################
#using NAmes as reference
logged1 <- lm(logprice~logarea100 +neighborhood,data = analysis1)
summary(logged1) #adj r^2 = 0.4857
#check residual histogram,shows not normal
ols_rsd_hist(logged1)
#check diagnostics
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(logged1)
analysis1$cookd <- cooks.distance(logged1)
analysis1 <- analysis1[order(-analysis1$cookd),] # remove the 2 highest value
########################deleting possible outlying points after observing the residual plot, assign it to analysis2###############################
analysis2 <- analysis1[-c(136,339),]
ggplot(analysis2, aes(x=logarea100, y=logprice, color = neighborhood))+
geom_point() + geom_smooth(method=lm)
######################### multiple regression with all neighborhoods, using logged data, without interactions ####################################
logged2<- lm(logprice~logarea100 +neighborhood,data = analysis2) # Edwards is not significant
summary(logged2) # adj r2 going from 0.4857 to 0.4919
vif(logged2)
confint(logged2)
ols_rsd_hist(logged2) #more normal
plot(logged2)
######################### multiple regression with all neighborhoods, using logged data, with interactions  ###########################################
########model for analysis1#################
loggedint <- lm(logprice~logarea100 +neighborhood + logarea100:neighborhood,data = analysis2)
summary(loggedint) #with interactions, adj r2 going from 0.4919 to 0.5074,all significant
vif(loggedint) #too big, need centering
plot(loggedint)
## the regression line is(when E=1 ,N=0, BrkSide is the reference here):
## log(price) = 9.74144 +0.79836 *logarea100 + 0.51298*E + 0.92964*N -0.21900 *(int1)  -0.32534*(int2)
## int1 = E*logarea100  | int2 = N*logarea100
analysis_final<- analysis2
analysis_final$fitted_final <- fitted(loggedint)
analysis_final$real_fitted <- exp(analysis_final$fitted_final)
confint(loggedint)
######################### multiple regression with all neighborhoods, using logged data, with centering  ###########################################
loggedintcenter <- lm(logprice~ neighborhood+I(logarea100-mean(logarea100))+neighborhood:I(logarea100-mean(logarea100)),data = analysis2)
summary(loggedintcenter)
vif(loggedintcenter)
plot(loggedintcenter)
## the VIF decreased a lot
## the regression line is(when E=1 ,N=0, BrkSide is the reference here):
## log(price) =   11.74745 -0.03728 *E  + 0.11218*N + 0.79836 *cent -0.21900*(E*cent) -0.32534 *(cent*N)
## center = logarea100-mean(logarea100)
########################################### treat BrkSide and Edwards the same encoding   ######################################################
######################### multiple regression with regrouping, using logged data, without interactions  ###########################################
analysis2$neighborhood2 <- ifelse(analysis2$neighborhood == "BrkSide"| analysis2$neighborhood =="Edwards", "B&E", "NAmes")
logged3 <- lm(logprice~logarea100 +neighborhood2,data = analysis2)
summary(logged3)
vif(logged3) #too big,centering
## the regression line is(when BE=1 ,N=0, BrkSide is the reference here):
## log(price) =10.06469 + 0.65923 *logarea100 + 0.60639 *N -0.18621*(int)
## int = N*logarea100
plot(logged3)
######################### multiple regression with regrouping, using logged data, with interactions  ###########################################
analysis2$neighborhood2 <- ifelse(analysis2$neighborhood == "BrkSide"| analysis2$neighborhood =="Edwards", "B&E", "NAmes")
loggedint2 <- lm(logprice~logarea100 +neighborhood2+ logarea100:neighborhood2,data = analysis2)
summary(loggedint2)
vif(loggedint2) #too big,centering
## the regression line is(when BE=1 ,N=0, BrkSide is the reference here):
## log(price) =10.06469 + 0.65923 *logarea100 + 0.60639 *N -0.18621*(int)
## int = N*logarea100
plot(loggedint2)
######################### multiple regression with regrouping, using logged data, with centering  ###########################################
loggedintcenter2 <- lm(logprice~ neighborhood2 + I(logarea100-mean(logarea100))+neighborhood2:I(logarea100-mean(logarea100)),data = analysis2)
summary(loggedintcenter2)
vif(loggedintcenter2)
## the VIF decreased a lot
## the regression line is(when BE=1 ,N=0, BrkSide is the reference here):
## log(price) =11.72113 + 0.13850*N +  0.65923* cent -0.18621*(cent*N)
## center = logarea100-mean(logarea100)
plot(loggedintcenter2)
############################ anova test to test whether regrouping and keeping all of them is different##########################
keep3 <- anova(loggedintcenter, loggedintcenter2,test="F")
keep3
#################################################        analysis 2           ####################################################
training2 <- training
colSums(is.na(training2))
colnames(training2)
drops <- c("Id","LotFrontage","Alley","MasVnrType","MasVnrArea","FireplaceQu","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2 ",
"FireplaceQu","GarageType " ," GarageYrBlt","GarageFinish","GarageQual","GarageCond","PoolQC","Fence","MiscFeature")
training_q2 <- training2[ , !(names(training2) %in% drops)]
fit <- lm(SalePrice ~ . , data=training_q2)
forward <-ols_stepaic_forward(fit,details = T)
#stop at step 37
forward_fit <-lm(SalePrice ~ GarageYrBlt + OverallQual + BsmtFinType2 +
GrLivArea + Neighborhood + KitchenQual + RoofMatl +
BsmtFinSF1 + MSSubClass + Condition2 + SaleCondition +
LotArea + ExterQual + OverallCond + YearBuilt + GarageArea +
PoolArea + TotalBsmtSF + KitchenAbvGr + Functional + Electrical +
LandSlope + BedroomAbvGr + BldgType + LandContour + Street + Condition1 +
GarageCars + ScreenPorch + SaleType + LowQualFinSF + RoofStyle + WoodDeckSF +
MoSold + Foundation + LotConfig + BsmtFinSF2 + BsmtUnfSF,data= training_q2)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
library(rvest)
library(XML)
library(RCurl)
library(plyr)
library(stringr)
library(xtable)
library(kableExtra)
install.packages("kableExtra")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
library(rvest)
library(XML)
library(RCurl)
library(plyr)
library(stringr)
library(xtable)
library(kableExtra)
procrastination_data <- read.csv("Data/Procrastination.csv",stringsAsFactors = FALSE)
kable(dim(procrastination_data), header = "Dimension of procrastination dataset")%>%
kable_styling(dim(procrastination_data),bootstrap_options='striped',full_width=FALSE)
